![[Pasted image 20220809163607.png]]
# TCP 和 UDP
**UDP**：-   **UDP 在传送数据之前不需要先建立连接**，远程主机在收到 UDP 报文后，不需要给出任何确认。
-   虽然 UDP **不提供可靠交付**，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等
**TCP(传输控制协议)和UDP（用户数据报协议）**

-   TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，是专门为了在不可靠的网络中提供一个可靠的端对端字节流而设计的，面向字节流。
-   UDP（用户数据报协议）是iso参考模型中一种无连接的传输层协议，提供简单不可靠的非连接传输层服务，面向报文

**区别：**
1.  TCP是面向连接的，可靠性高；UDP是基于非连接的，可靠性低
2.  由于TCP是连接的通信，需要有三次握手、重新确认等连接过程，会有延时，实时性差，同时过程复杂，也使其易于攻击；UDP没有建立连接的过程，因而实时性较强，也稍安全
3.  在传输相同大小的数据时，TCP首部开销20字节；UDP首部开销8字节，TCP报头比UDP复杂，故实际包含的用户数据较少。TCP在IP协议的基础上添加了序号机制、确认机制、超时重传机制等，保证了传输的可靠性，不会出现丢包或乱序，而UDP有丢包，故TCP开销大，UDP开销较小
4.  每条TCP连接只能时点到点的；UDP支持一对一、一对多、多对一、多对多的交互通信

**应用场景选择**
-   对实时性要求高和高速传输的场合下使用UDP;在可靠性要求低，追求效率的情况下使用UDP;
-   需要传输大量数据且对可靠性要求高的情况下使用TCP
# TCP三次握手四次挥手
两个目的：
1.  确保建立可靠连接
2.  避免资源浪费

TCP是一种面向连接的单播协议，在发送数据前，通信双方必须在彼此间建立一条连接。所谓的“连接”，其实是客户端和服务器的内存里保存的一份关于对方的信息，如ip地址、端口号等。
TCP提供了一种可靠、面向连接、字节流、传输层的服务，采用三次握手建立一个连接。采用4次挥手来关闭一个连接。
## 三次握手：
作用就是`双方都能明确自己和对方的收、发能力是正常的`，确认序列号。
![[Pasted image 20220730115307.png]]
 **刚开始客户端处于 `Closed` 的状态，而服务端处于 `Listen` 状态**：

> `CLOSED` ：没有任何连接状态
> 
> `LISTEN` ：侦听来自远方 TCP 端口的连接请求

**1）第一次握手**：客户端向服务端发送一个 SYN 报文（SYN = 1），并指明客户端的初始化序列号 ISN(x)，即图中的 seq = x，表示本报文段所发送的数据的第一个字节的序号。此时客户端处于 `SYN_Send` 状态。

> `SYN-SENT` ：在发送连接请求后等待匹配的连接请求

**2）第二次握手**：服务器收到客户端的 SYN 报文之后，会发送 SYN 报文作为应答（SYN = 1），并且指定自己的初始化序列号 ISN(y)，即图中的 seq = y。同时会把客户端的 ISN + 1 作为确认号 ack 的值，表示已经收到了客户端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 x + 1，此时服务器处于 `SYN_REVD` 的状态。

> `SYN-RECEIVED`：在收到和发送一个连接请求后等待对连接请求的确认

**3）第三次握手**：客户端收到服务器端响应的 SYN 报文之后，会发送一个 ACK 报文，也是一样把服务器的 ISN + 1 作为 ack 的值，表示已经收到了服务端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 y + 1，并指明此时客户端的序列号 seq = x + 1（初始为 seq = x，所以第二个报文段要 +1），此时客户端处于 `Establised` 状态。

服务器收到 ACK 报文之后，也处于 `Establised 状态`，至此，双方建立起了 TCP 连接。

> `ESTABLISHED`：代表一个打开的连接，数据可以传送给用户
>

## 四次挥手
为了关闭双工，**半关闭**（half-close）特性造成的，TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。
![[Pasted image 20220730115727.png]]
刚开始双方都处于`ESTABLISHED` 状态，假设是客户端先发起关闭请求。四次挥手的过程如下：
**1）第一次挥手**：客户端发送一个 FIN 报文（请求连接终止：FIN = 1），报文中会指定一个序列号 seq = u。并**停止再发送数据，主动关闭 TCP 连接**。此时客户端处于 `FIN_WAIT1` 状态，等待服务端的确认。

> `FIN-WAIT-1` - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；

**2）第二次挥手**：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 `CLOSE_WAIT` 状态。

> `CLOSE-WAIT` - 等待从本地用户发来的连接中断请求；

**此时的 TCP 处于半关闭状态，客户端到服务端的连接释放**。客户端收到服务端的确认后，进入`FIN_WAIT2`（终止等待 2）状态，等待服务端发出的连接释放报文段。

> `FIN-WAIT-2` - 从远程TCP等待连接中断请求；

**3）第三次挥手**：如果服务端也想断开连接了（没有要向客户端发出的数据），和客户端的第一次挥手一样，发送 FIN 报文，且指定一个序列号。此时服务端处于 `LAST_ACK` 的状态，等待客户端的确认。

> `LAST-ACK` - 等待原来发向远程TCP的连接中断请求的确认；

**4）第四次挥手**：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答（ack = w+1），且把服务端的序列值 +1 作为自己 ACK 报文的序号值（seq=u+1），此时客户端处于 **`TIME_WAIT` （时间等待）状态**。

> `TIME-WAIT` - 等待足够的时间以确保远程TCP接收到连接中断请求的确认；

🚨 注意 ！！！这个时候由服务端到客户端的 TCP 连接并未释放掉，**需要经过时间等待计时器设置的时间 2MSL（一个报文的来回时间） 后才会进入 `CLOSED` 状态**（这样做的目的是确保服务端收到自己的 ACK 报文。如果服务端在规定时间内没有收到客户端发来的 ACK 报文的话，服务端会重新发送 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文给服务端）。服务端收到 ACK 报文之后，就关闭连接了，处于 `CLOSED` 

# HTTPS加密解密流程
**Http**是一个简单的请求-响应协议，它通常运行在[TCP](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/TCP/33012%3Ffr%3Daladdin)之上。，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议。（它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。请求和响应消息的头以ASCII码形式给出；而消息内容则具有一个类似MIME的格式。这个简单模型是早期Web成功的有功之臣，因为它使开发和部署非常地直截了当。）端口号80

**Https**在HTTP的基础上通过**传输加密和身份认证保证了**传输过程的安全性 。加入SSL（安全套接字层）层。安全敏感的通讯，例如交易支付等方面。端口号443

**https加密解密流程**分成以下8个步骤：

1.  **客户端发起HTTPS请求** 这个没什么好说的，就是用户在浏览器里输入一个HTTPS网址，然后连接到服务端的443端口。
2.  **服务端的配置** 采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。这套证书其实就是一对公钥和私钥。如果对公钥不太理解，可以想象成一把钥匙和一个锁头，只是世界上只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。
3.  **传送证书** 这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。
4.  **客户端解析证书** 这部分工作是由客户端的SSL/TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警示框，提示证书存在的问题。如果证书没有问题，那么就生成一个**随机值**。然后用证书（也就是公钥）对这个随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。
5.  **传送加密信息** 这部分传送的是用证书加密后的随机值，目的是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
6.  **服务端解密信息** 服务端用私钥解密后，得到了客户端传过来的随机值，然后把内容通过该随机值进行对称加密，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。
7.  **传输加密后的信息** 这部分信息就是服务端用私钥加密后的信息，可以在客户端用随机值解密还原。
8.  **客户端解密信息** 客户端用之前生产的私钥解密服务端传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。
### 三次握手
三次握手：作用就是`双方都能明确自己和对方的收、发能力是正常的`，确认序列号。
1.A->B SYN=1,seq=x B
2.B->A SYN=1,seq=y;ACK=1,ack=x+1
3.A->B ACK=1,ack=y+1
### 四次挥手
为了关闭双工，**半关闭**（half-close）特性造成的，TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。
1.A->B Fin=1,seq=u
2.B->A ACK=1,ack=u+1,seq=v
一些B->A的数据发送
3.B->A FIN=1,seq=w,ACK=1,ack=u+1
4.A->B ACK=1,seq=u+1,ack=w+1

seq:我方（发送方）这边，这个packet的数据部分的第一位应该在整个data stream中所在的位置。
ack:期望的对方（接收方）的下一次sequence number是多少

等待计时器设置的时间 2MSL（一个报文的来回时间） 后才会进入 `CLOSED` 状态**（这样做的目的是确保服务端收到自己的 ACK 报文。如果服务端在规定时间内没有收到客户端发来的 ACK 报文的话，服务端会重新发送 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文给服务端

# http 缓存策略
-   浏览器每次发起请求时，先在本地缓存中查找结果以及缓存标识，根据缓存标识来判断是否使用本地缓存。如果缓存有效，则使用本地缓存；否则，则向服务器发起请求并携带缓存标识。根据是否需向服务器发起HTTP请求，将缓存过程划分为两个部分：  
    强制缓存和协商缓存，强缓优先于协商缓存。    
    -   强缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。
    -   协商缓存，让客户端与服务器之间能实现缓存文件是否更新的验证、提升缓存的复用率，将缓存信息中的Etag和Last-Modified通过请求发送给服务器，由服务器校验，返回304状态码时，浏览器直接使用缓存。
    HTTP缓存都是从第二次请求开始的：
    -   第一次请求资源时，服务器返回资源，并在response header中回传资源的缓存策略；
    -   第二次请求时，浏览器判断这些请求参数，击中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否击中协商缓存，击中则返回304，否则服务器会返回新的资源。这是缓存运作的一个整体流程图：
        ![](https://uploadfiles.nowcoder.com/images/20220301/4107856_1646127327951/FAA50E4B64035E031660B7B26EB16978)
        
-   **强缓存**
    
    -   强缓存命中则直接读取浏览器本地的资源，在network中显示的是from memory或者from disk
    -   控制强制缓存的字段有：Cache-Control（http1.1）和Expires（http1.0）
    -   Cache-control是一个相对时间，用以表达自上次请求正确的资源之后的多少秒的时间段内缓存有效。
    -   Expires是一个绝对时间。用以表达在这个时间点之前发起请求可以直接从浏览器中读取数据，而无需发起请求
    -   Cache-Control的优先级比Expires的优先级高。前者的出现是为了解决Expires在浏览器时间被手动更改导致缓存判断错误的问题。  
        如果同时存在则使用Cache-control。
-   **强缓存-expires**
    
    -   该字段是服务器响应消息头字段，告诉浏览器在过期时间之前可以直接从浏览器缓存中存取数据。
    -   Expires 是 HTTP 1.0 的字段，表示缓存到期时间，是一个绝对的时间 (当前时间+缓存时间)。在响应消息头中，设置这个字段之后，就可以告诉浏览器，在未过期之前不需要再次请求。
    -   由于是绝对时间，用户可能会将客户端本地的时间进行修改，而导致浏览器判断缓存失效，重新请求该资源。此外，即使不考虑修改，时差或者误差等因素也可能造成客户端与服务端的时间不一致，致使缓存失效。
    -   优势特点
        -   HTTP 1.0 产物，可以在HTTP 1.0和1.1中使用，简单易用。
        -   以时刻标识失效时间。
    -   劣势问题
        -   时间是由服务器发送的(UTC)，如果服务器时间和客户端时间存在不一致，可能会出现问题。
        -   存在版本问题，到期之前的修改客户端是不可知的。
-   **强缓存-cache-control**
    
    -   已知Expires的缺点之后，在HTTP/1.1中，增加了一个字段Cache-control，该字段表示资源缓存的最大有效时间，在该时间内，客户端不需要向服务器发送请求。
    -   这两者的区别就是前者是绝对时间，而后者是相对时间。下面列举一些Cache-control字段常用的值：(完整的列表可以查看MDN)
        -   max-age：即最大有效时间。
        -   must-revalidate：如果超过了max-age的时间，浏览器必须向服务器发送请求，验证资源是否还有效。
        -   no-cache：不使用强缓存，需要与服务器验证缓存是否新鲜。
        -   no-store: 真正意义上的“不要缓存”。所有内容都不走缓存，包括强制和对比。
        -   public：所有的内容都可以被缓存 (包括客户端和代理服务器， 如 CDN)
        -   private：所有的内容只有客户端才可以缓存，代理服务器不能缓存。默认值。
    -   **Cache-control 的优先级高于 Expires**，为了兼容 HTTP/1.0 和 HTTP/1.1，实际项目中两个字段都可以设置。
    -   该字段可以在请求头或者响应头设置，可组合使用多种指令：
        -   可缓存性
            -   public：浏览器和缓存服务器都可以缓存页面信息
            -   private：default，代理服务器不可缓存，只能被单个用户缓存
            -   no-cache：浏览器器和服务器都不应该缓存页面信息，但仍可缓存，只是在缓存前需要向服务器确认资源是否被更改。可配合private，  
                过期时间设置为过去时间。
            -   only-if-cache：客户端只接受已缓存的响应
        -   到期
            -   max-age=：缓存存储的最大周期，超过这个周期被认为过期。
            -   s-maxage=：设置共享缓存，比如can。会覆盖max-age和expires。
            -   max-stale[=]：客户端愿意接收一个已经过期的资源
            -   min-fresh=：客户端希望在指定的时间内获取最新的响应
            -   stale-while-revalidate=：客户端愿意接收陈旧的响应，并且在后台一部检查新的响应。时间代表客户端愿意接收陈旧响应  
                的时间长度。
            -   stale-if-error=：如新的检测失败，客户端则愿意接收陈旧的响应，时间代表等待时间。
        -   重新验证和重新加载
            -   must-revalidate：如页面过期，则去服务器进行获取。
            -   proxy-revalidate：用于共享缓存。
            -   immutable：响应正文不随时间改变。
        -   其他
            -   no-store：绝对禁止缓存
            -   no-transform：不得对资源进行转换和转变。例如，不得对图像格式进行转换。
    -   优势特点
        -   HTTP 1.1 产物，以时间间隔标识失效时间，解决了Expires服务器和客户端相对时间的问题。
        -   比Expires多了很多选项设置。
    -   劣势问题
        -   存在版本问题，到期之前的修改客户端是不可知的。
-   **协商缓存**
    
    -   协商缓存的状态码由服务器决策返回200或者304
    -   当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了If-Modified-Since 或者 If-None-Match 的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 Last-Modified 或者 ETag 属性。
    -   对比缓存在请求数上和没有缓存是一致的，但如果是 304 的话，返回的仅仅是一个状态码而已，并没有实际的文件内容，因此 在响应体体积上的节省是它的优化点。
    -   协商缓存有 2 组字段(不是两个)，控制协商缓存的字段有：Last-Modified/If-Modified-since（http1.0）和Etag/If-None-match（http1.1）
    -   Last-Modified/If-Modified-since表示的是服务器的资源最后一次修改的时间；Etag/If-None-match表示的是服务器资源的唯一标  
        识，只要资源变化，Etag就会重新生成。
    -   Etag/If-None-match的优先级比Last-Modified/If-Modified-since高。
-   **协商缓存-协商缓存-Last-Modified/If-Modified-since**
    
    -   服务器通过Last-Modified字段告知客户端，资源最后一次被修改的时间，例如Last-Modified: Mon, 10 Nov 2018 09:10:11 GMT
    -   浏览器将这个值和内容一起记录在缓存数据库中。
    -   下一次请求相同资源时时，浏览器从自己的缓存中找出“不确定是否过期的”缓存。因此在请求头中将上次的Last-Modified的值写入到请求头的If-Modified-Since字段
    -   服务器会将If-Modified-Since的值与Last-Modified字段进行对比。如果相等，则表示未修改，响应 304；反之，则表示修改了，响应 200 状态码，并返回数据。
    -   优势特点
        -   不存在版本问题，每次请求都会去服务器进行校验。服务器对比最后修改时间如果相同则返回304，不同返回200以及资源内容。
    -   劣势问题
        -   只要资源修改，无论内容是否发生实质性的变化，都会将该资源返回客户端。例如周期性重写，这种情况下该资源包含的数据实际上一样的。
        -   以时刻作为标识，无法识别一秒内进行多次修改的情况。 如果资源更新的速度是秒以下单位，那么该缓存是不能被使用的，因为它的时间单位最低是秒。
        -   某些服务器不能精确的得到文件的最后修改时间。
        -   如果文件是通过服务器动态生成的，那么该方法的更新时间永远是生成的时间，尽管文件可能没有变化，所以起不到缓存的作用。
-   **协商缓存-Etag/If-None-match**
    
    -   为了解决上述问题，出现了一组新的字段Etag和If-None-Match
    -   Etag存储的是文件的特殊标识(一般都是 hash 生成的)，服务器存储着文件的Etag字段。之后的流程和Last-Modified一致，只是Last-Modified字段和它所表示的更新时间改变成了Etag字段和它所表示的文件 hash，把If-Modified-Since变成了If-None-Match。服务器同样进行比较，命中返回 304, 不命中返回新资源和 200。
    -   浏览器在发起请求时，服务器返回在Response header中返回请求资源的唯一标识。在下一次请求时，会将上一次返回的Etag值赋值给If-No-Matched并添加在Request Header中。服务器将浏览器传来的if-no-matched跟自己的本地的资源的ETag做对比，如果匹配，则返回304通知浏览器读取本地缓存，否则返回200和更新后的资源。
    -   **Etag 的优先级高于 Last-Modified**。
    -   优势特点
        -   可以更加精确的判断资源是否被修改，可以识别一秒内多次修改的情况。
        -   不存在版本问题，每次请求都回去服务器进行校验。
    -   劣势问题
        -   计算ETag值需要性能损耗。
        -   分布式服务器存储的情况下，计算ETag的算法如果不一样，会导致浏览器从一台服务器上获得页面内容后到另外一台服务器上进行验证时现ETag不匹配的情况。

### HTTP1.0 2.0 3.0
https://www.51cto.com/article/628901.html
#### 1.0
1.0的HTTP版本，是一种无状态，无连接的应用层协议。 HTTP1.0规定浏览器和服务器保持短暂的链接。
浏览器每次请求都需要与服务器建立一个TCP连接，服务器处理完成以后立即断开TCP连接(无连接)，服务器不跟踪也每个客户单，也不记录过去的请求(无状态)。
这种无状态性可以借助cookie/session机制来做身份认证和状态记录。
**存在的问题**：
1.无法复用连接
每次发送请求，都需要进行一次TCP连接，而TCP的连接释放过程又是比较费事的。这种无连接的特性会使得网络的利用率变低。
2.队头阻塞
规定下一个请求必须在前一个请求响应到达之前才能发送，假设前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了
#### 1.1
**改变**
1.长连接
增加Connection字段，设置Keep-Alive保持HTTP连接不断。避免每次请求重复建立释放建立TCP连接。提高网络的利用率。
客户端想关闭连接，请求头Connection:false告知服务器。
2.请求管道化(pipelining)
假并行传输：服务器必须按照客户端请求的先后顺序依次回送相应的结果，可以让我们把先进先出队列从客户端(请求队列)迁移到服务端(响应队列)
3.缓存处理 — 强缓存、协商缓存，启发式缓存(新增)
加入了缓存处理(强缓存和协商缓存)，新的字段如cache-control，支持断点传输，以及增加了Host字段(使得一个服务器能够用来创建多个Web站点)
#### 2.0
1.二进制分帧
通过在应用层和传输层之间增加一个二进制分层帧，突破了HTTP1.1的性能限制，改进传输性能。
2.多路复用(链接共享)— 真并行传输
所有HTTP2.0通信都在一个TCP链接上完成，这个链接可以承载任意流量的双向数据流。
每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符(Stream_id)重新封装。
多路复用(连接共享)可能会导致关键字被阻塞，HTTP2.0里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回客户端，数据流还可以依赖其他的子数据流。
可见，HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量的HTTP请求。而这个强大的功能基于“二级制分帧”的特性。
3.头部压缩
在HTTP1.X中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500-8000字节的负荷。
2.0使用encoder来减少的header大小，通讯双方各自cache一份header_files表，既避免重复header的传输，又减少了需要传输的大小。
高效的压缩算法可以很大的压缩header，减少发送包的数量从而降低延迟。
4.服务器推送
额外向客户端推送静态资源

#### 3.0
https://www.51cto.com/article/625999.html
基于UDP协议的QUIC协议
1**.0-RTT 缓存当前会话的上下文**
RTT:衡量网络建链的常用指标是 Round-Trip Time，也就是数据包一来一回的时间消耗。
	缓存当前会话的上下文，下次恢复会话的时候，只需要将之前的缓存传递给服务器，验证通过，就可以进行传输了。
	0-RTT建连可以说是QUIC相比HTTP2最大的性能优势。
	什么是0-RTT建连?
	1.传输层0-RTT就能建立连接
	2.加密层0-RTT就能建立加密连接
简单来说，基于TCP协议和TLS协议的HTTP2.0在真正发送数据包之前需要花费一些时间来完成**握手和加密协商**，完成之后才可以真正传输业务数据。
但是QUIC则**第一个数据包就可以发业务数据**，从而在连接延时有很大优势，可以节约数百毫秒的时间。
2.**多路复用**
QUIC基于UDP，一个连接上的多个stream之间没有依赖，即使丢包，只需要重发丢失的包即可，不需要重传整个连接。
3.**更好的移动端表现**
因为TCP是基于IP识别连接，而QUIC是通过ID识别链接。 无论网络环境如何变化，只要ID不便，就能迅速重新连上。
TCP协议使用五元组来表示一条唯一的连接，当我们从4G环境切换到wifi环境时，手机的IP地址就会发生变化，这时必须创建新的TCP连接才能继续传输数据。
QUIC协议基于UDP实现摒弃了五元组的概念，使用64位的随机数作为连接的ID，并使用该ID表示连接。
基于QUIC协议之下，我们在日常wifi和4G切换时，或者不同基站之间切换都不会重连，从而提高业务层的体验。
4.**加密认证报文头部、body**
TCP协议头没有经过任何加密和认证
对 QUIC 做任何更改，接收端都能及时发现，有效地降低了安全风险
5.**前向安全&&前向纠错机制**
少量的丢包可以通过其他包的冗余数据直接组装而无需重传
**总结**
QUIC协议的核心思想是将TCP协议在内核实现的诸如可靠传输、流量控制、拥塞控制等功能转移到用户态来实现，同时在加密传输方向的尝试也推动了TLS1.3的发展。
#### 常见问题
1.**HTTP1.1的合并请求(如CSSsprites)是否适用于HTTP2.0**
没有必要。
在头部压缩技术中，客户端和服务器均会维护两份相同的静态字典和动态字典。
在静态字典中，包含了常见的头部名称与值的组合。静态字典在首次请求时可以使用。那么现在头部的字段就可以被简写成静态字典中相应字段的index。
而动态字典跟连接的上下文相关，每个HTTP/2连接维护的动态字典不尽相同。动态字典可以在连接不停地进行更新。
也就是说，原本完整的HTTP报文头部的键值或字段，由于字典的存在，现在可以转换成索引index，在相应的端再进行查找还原，也就起到了压缩的作用。
所以，**同一个链接上产生的请求和响应越多，动态字典累积得越全，头部压缩的效果也就越好，所以针对HTTP/2网站，最佳实践是不要合并资源。**
另外，HTTP2.0多路复用，使得请求可以并行传输，而HTTP1.1合并请求的一个原因也是为了防止过多的HTTP请求带来的阻塞问题。而现在HTTP2.0已经能够并行传输了，所以合并请求也就没有必要了。
2.**为什么要3.0，为什么UDP**
(1 2.0缺点
	(1)建立连接时间长(本质上是TCP的问题)
	(2)队头阻塞问题
	(3)移动互联网领域表现不佳(弱网环境)
   这些缺点基本都是由于TCP协议引起的
(2 TCP协议的不足和UDP的一些优点：
	(1)基于TCP开发的设备和协议非常多，兼容困难
	(2)TCP协议栈是Linux内部的重要部分，修改和升级成本很大
	(3)UDP本身是无连接的、没有建链和拆链成本
	(4)UDP的数据包无队头阻塞问题
	(5)UDP改造成本小

3.**http2是如何解决tcp的队首阻塞的？**
HTTP/2 并没有解决 TCP 的队首阻塞问题，它仅仅是通过**多路复用**解决了以前 HTTP1.1 **管线化**请求时的队首阻塞。

比如 HTTP/1.1 时代建立一个 TCP 连接，三个请求组成一个队列发出去，服务器接收到这个队列之后会依次响应，一旦前面的请求阻塞，后面的请求就会无法响应。

HTTP/2 是通过**分帧**并且给每个帧打上**流**的 ID 去避免依次响应的问题，对方接收到帧之后根据 ID 拼接出流，这样就可以做到乱序响应从而避免请求时的队首阻塞问题。但是 TCP 层面的队首阻塞是 HTTP/2 无法解决的（HTTP 只是应用层协议，TCP 是传输层协议），TCP 的阻塞问题是因为传输阶段可能会丢包，一旦丢包就会等待重新发包，阻塞后续传输，这个问题虽然有**滑动窗口（Sliding Window）**这个方案，但是只能增强抗干扰，并没有彻底解决。

 **总结**
**HTTP 1.0**
-无状态，无连接
-短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能
-无host头域，也就是http请求头里的host，
-不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象
**HTTP 1.1**
-长连接，流水线，使用connection:keep-alive使用长连接
-请求管道化
-增加缓存处理(新的字段如cache-control)
-增加Host字段，支持断点传输等
-由于长连接会给服务器造成压力
**HTTP 2.0**
-二进制分帧
-头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小
-多路复用(或连接共享)，使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求
-服务器推送(Sever push)
**HTTP 3.0**
-基于google的QUIC协议，而quic协议是使用udp实现的
-0-rtt,减少了tcp三次握手时间，以及tls握手时间
-解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题
-优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗
-连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接
-更合适的流量控制
-基于UDP的多路复用
-加密认证的报文
-向前纠错机制







